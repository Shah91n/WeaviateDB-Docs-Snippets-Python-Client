{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the weaviate client\n",
    "%pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "from weaviate.config import AdditionalConfig, Timeout\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "CLUSTER_URL = os.getenv(\"CLUSTER_URL\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Connect to Weaviate\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "\tcluster_url=CLUSTER_URL,\n",
    "\tauth_credentials=weaviate.auth.AuthApiKey(API_KEY),\n",
    "\theaders={\n",
    "\t\t\"X-OpenAI-Api-Key\": OPENAI_API_KEY,\n",
    "\t\t\"X-Cohere-Api-Key\": COHERE_API_KEY,\n",
    "        \"X-Goog-Api-Key\": GOOGLE_API_KEY\n",
    "\t},\n",
    "\tadditional_config=AdditionalConfig(\n",
    "\t\ttimeout=Timeout(init=30, query=60, insert=120)\n",
    "\t)\n",
    ")\n",
    "\n",
    "ready = client.is_ready()\n",
    "server_version = client.get_meta()[\"version\"]\n",
    "client_version = weaviate.__version__\n",
    "live = client.is_live()\n",
    "connected = client.is_connected()\n",
    "\n",
    "print(f\"Weaviate Ready: {ready}\")\n",
    "print(f\"Weaviate Client Version: {client_version}\")\n",
    "print(f\"Weaviate Server Version: {server_version}\")\n",
    "print(f\"Weaviate Live: {client.is_live()}\")\n",
    "print(f\"Client Connected: {connected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your query vector (the same vector from your GraphQL query)\n",
    "query_vector = [0.1, 0.2, 0.3, 0.4, 0.5]  # Replace with your actual vector\n",
    "# Get the collection\n",
    "collection = client.collections.get(\"MyCollection\")\n",
    "\n",
    "# Perform the near vector query\n",
    "response = collection.query.near_vector(\n",
    "    near_vector=query_vector,\n",
    "    limit=1\n",
    ")\n",
    "\n",
    "# Print the results\n",
    "for obj in response.objects:\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use OpenAI to generate an embedding for a word\n",
    "from openai import OpenAI\n",
    "\n",
    "oa_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def embed(word: str):\n",
    "    resp = oa_client.embeddings.create(model=\"text-embedding-3-small\", input=word)\n",
    "    return resp.data[0].embedding\n",
    "\n",
    "vector = embed(\"\")\n",
    "print(f\"Vector dimensionality: {len(vector)}\")\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
