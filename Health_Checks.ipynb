{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the weaviate client\n",
    "%pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate, os\n",
    "from weaviate.config import AdditionalConfig, Timeout\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve environment variables\n",
    "CLUSTER_URL = os.getenv(\"CLUSTER_URL\")\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Connect to Weaviate\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "\tcluster_url=CLUSTER_URL,\n",
    "\tauth_credentials=weaviate.auth.AuthApiKey(API_KEY),\n",
    "\theaders={\n",
    "\t\t\"X-OpenAI-Api-Key\": OPENAI_API_KEY,\n",
    "\t\t\"X-Cohere-Api-Key\": COHERE_API_KEY,\n",
    "        \"X-Goog-Api-Key\": GOOGLE_API_KEY\n",
    "\t},\n",
    "\tadditional_config=AdditionalConfig(\n",
    "\t\ttimeout=Timeout(init=30, query=60, insert=120)\n",
    "\t)\n",
    ")\n",
    "\n",
    "ready = client.is_ready()\n",
    "server_version = client.get_meta()[\"version\"]\n",
    "client_version = weaviate.__version__\n",
    "live = client.is_live()\n",
    "connected = client.is_connected()\n",
    "\n",
    "print(f\"Weaviate Ready: {ready}\")\n",
    "print(f\"Weaviate Client Version: {client_version}\")\n",
    "print(f\"Weaviate Server Version: {server_version}\")\n",
    "print(f\"Weaviate Live: {client.is_live()}\")\n",
    "print(f\"Client Connected: {connected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Collection Count Check ---\n",
    "\n",
    "# Retrieve the list of all collection names\n",
    "_all = client.collections.list_all()              # dict: {name: _CollectionConfigSimple, ...}\n",
    "all_collections = list(_all.keys())               # list[str]\n",
    "number_of_collections = len(all_collections)\n",
    "\n",
    "print(f\"Number of collections: {number_of_collections}\")\n",
    "\n",
    "# Warn if the number of collections is above a typical threshold. \n",
    "# This can indicate an anti-pattern in schema design.\n",
    "if number_of_collections > 100:\n",
    "    print(\"Warning: You have a lot of collections.\")\n",
    "    print(\"Consider using Weaviate Multitenancy (multi-tenant collection) for better scalability,\")\n",
    "    print(\"especially if many collections are configured identically but represent different users, groups etc... \")\n",
    "else:\n",
    "    print(\"You have a reasonable number of collections.\")\n",
    "\n",
    "# --- End Collection Count Check ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "ALLOWED_DELETE = {\"TimeBasedResolution\", \"DeleteOnConflict\"}\n",
    "\n",
    "try:\n",
    "\tresp = requests.get(f\"{CLUSTER_URL}/v1/schema\", headers={\"Authorization\": f\"Bearer {API_KEY}\"}, timeout=15)\n",
    "\tresp.raise_for_status()\n",
    "\tschema = resp.json()\n",
    "except Exception as e:\n",
    "\tprint(\"Failed to fetch schema:\", e)\n",
    "\tschema = {}\n",
    "\n",
    "rows = []\n",
    "for cls in schema.get(\"classes\", []):\n",
    "\tname = cls.get(\"class\")\n",
    "\trep = cls.get(\"replicationConfig\", {}) or {}\n",
    "\tasync_enabled = rep.get(\"asyncEnabled\")\n",
    "\tdeletion_strategy = rep.get(\"deletionStrategy\") or rep.get(\"deletion_strategy\")\n",
    "\tfactor = rep.get(\"factor\")\n",
    "\n",
    "\tok_async = (async_enabled is True)\n",
    "\tok_delete = deletion_strategy in ALLOWED_DELETE\n",
    "\n",
    "\trows.append(\n",
    "\t\tf\"- {name}: factor={factor if factor is not None else 'N/A'} | \"\n",
    "\t\tf\"async={'True' if async_enabled is True else str(async_enabled)}\"\n",
    "\t\tf\"{' (OK)' if ok_async else ' -> ENABLE True'} | \"\n",
    "\t\tf\"delete={deletion_strategy}\"\n",
    "\t\tf\"{' (OK)' if ok_delete else ' -> SET TimeBasedResolution/DeleteOnConflict'}\"\n",
    "\t)\n",
    "\n",
    "for line in rows:\n",
    "\tprint(line)\n",
    "\n",
    "print()\n",
    "print(\"Note: replication factor should match number of data nodes. 3 is common; if\")\n",
    "print(\"you run 5, 7, or 9 nodes, set factor to 5, 7, or 9 respectively.\")\n",
    "print()\n",
    "print(\"Deletion resolution strategies:\")\n",
    "print(\"- TimeBasedResolution: last write wins using timestamps (delete/create/update).\")\n",
    "print(\"- DeleteOnConflict: any replica reporting a delete deletes it cluster-wide.\")\n",
    "print(\"Use TimeBasedResolution for last-write-wins; use DeleteOnConflict to always honor deletes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration Similarity Check (REST schema) ---\n",
    "import json\n",
    "import requests\n",
    "\n",
    "try:\n",
    "\tresp = requests.get(f\"{CLUSTER_URL}/v1/schema\", headers={\"Authorization\": f\"Bearer {API_KEY}\"}, timeout=15)\n",
    "\tresp.raise_for_status()\n",
    "\tschema = resp.json()\n",
    "except Exception as e:\n",
    "\tprint(\"Failed to fetch schema:\", e)\n",
    "\tschema = {\"classes\": []}\n",
    "\n",
    "\n",
    "def normalize_for_grouping(cls_obj):\n",
    "\t\"\"\"Pick only core knobs and serialize deterministically for grouping.\n",
    "\tIncludes: replicationConfig, invertedIndexConfig, shardingConfig, vectorConfig (incl. vectorizer details).\n",
    "\t\"\"\"\n",
    "\trep = cls_obj.get(\"replicationConfig\", {}) or {}\n",
    "\tinv = cls_obj.get(\"invertedIndexConfig\", {}) or {}\n",
    "\tshard = cls_obj.get(\"shardingConfig\", {}) or {}\n",
    "\tvec = cls_obj.get(\"vectorConfig\", {}) or {}\n",
    "\n",
    "\t# Normalize vector config including provider details\n",
    "\tnorm_vec = {}\n",
    "\tfor name, cfg in sorted(vec.items()):\n",
    "\t\tv = cfg.get(\"vectorizer\") or {}\n",
    "\t\tif isinstance(v, dict) and v:\n",
    "\t\t\tprovider = next(iter(v.keys()))\n",
    "\t\t\tdetails = v.get(provider) or {}\n",
    "\t\t\tnorm_vec[name] = {\n",
    "\t\t\t\t\"provider\": provider,\n",
    "\t\t\t\t\"model\": details.get(\"model\"),\n",
    "\t\t\t\t\"baseURL\": details.get(\"baseURL\"),\n",
    "\t\t\t\t\"vectorizeClassName\": details.get(\"vectorizeClassName\"),\n",
    "\t\t\t\t\"properties\": details.get(\"properties\", []),\n",
    "\t\t\t\t\"vectorIndexType\": cfg.get(\"vectorIndexType\"),\n",
    "\t\t\t\t\"vectorIndexConfig\": cfg.get(\"vectorIndexConfig\", {}),\n",
    "\t\t\t}\n",
    "\t\telse:\n",
    "\t\t\tnorm_vec[name] = {\"provider\": v, \"vectorIndexType\": cfg.get(\"vectorIndexType\"), \"vectorIndexConfig\": cfg.get(\"vectorIndexConfig\", {})}\n",
    "\n",
    "\tnorm = {\n",
    "\t\t\"replicationConfig\": rep,\n",
    "\t\t\"invertedIndexConfig\": inv,\n",
    "\t\t\"shardingConfig\": shard,\n",
    "\t\t\"vectorConfig\": norm_vec,\n",
    "\t}\n",
    "\t# Deterministic signature\n",
    "\treturn json.dumps(norm, sort_keys=True, separators=(\",\", \":\"))\n",
    "\n",
    "classes = schema.get(\"classes\", [])\n",
    "if not classes:\n",
    "\tprint(\"No collections found.\")\n",
    "else:\n",
    "\tgroups = {}\n",
    "\tfor c in classes:\n",
    "\t\tname = c.get(\"class\")\n",
    "\t\tsig = normalize_for_grouping(c)\n",
    "\t\tgroups.setdefault(sig, []).append(name)\n",
    "\n",
    "\tif len(groups) == 1:\n",
    "\t\tonly_group = next(iter(groups.values()))\n",
    "\t\tprint(\"All collections share identical core settings (replication, inverted index, sharding, vector/vectorizer).\")\n",
    "\t\tprint(\"These look like candidates for a single multi-tenant collection.\")\n",
    "\t\tprint(\"Collections:\", \", \".join(sorted(only_group)))\n",
    "\telse:\n",
    "\t\tprint(f\"Found {len(groups)} configuration groups:\")\n",
    "\t\tfor idx, names in enumerate(groups.values(), start=1):\n",
    "\t\t\tprint(f\"  Group {idx} ({len(names)}):\", \", \".join(sorted(names)))\n",
    "\n",
    "# --- End Configuration Similarity Check ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Replication & Compression Check (REST schema) ---\n",
    "import requests\n",
    "\n",
    "try:\n",
    "\tresp = requests.get(f\"{CLUSTER_URL}/v1/schema\", headers={\"Authorization\": f\"Bearer {API_KEY}\"}, timeout=15)\n",
    "\tresp.raise_for_status()\n",
    "\tschema = resp.json()\n",
    "except Exception as e:\n",
    "\tprint(\"Failed to fetch schema:\", e)\n",
    "\tschema = {\"classes\": []}\n",
    "\n",
    "for cls in schema.get(\"classes\", []):\n",
    "\tname = cls.get(\"class\")\n",
    "\trep = cls.get(\"replicationConfig\", {}) or {}\n",
    "\tfactor = rep.get(\"factor\")\n",
    "\n",
    "\t# Determine compression:\n",
    "\t# 1) Class-level vectorIndexConfig (as in text2vec-openai/simple vectorizer cases)\n",
    "\tcompression_enabled = False\n",
    "\twhich = []\n",
    "\tvic_root = cls.get(\"vectorIndexConfig\", {}) or {}\n",
    "\tfor key in (\"bq\", \"pq\", \"rq\", \"sq\"):\n",
    "\t\tsub = vic_root.get(key) or {}\n",
    "\t\tif sub.get(\"enabled\") is True:\n",
    "\t\t\tcompression_enabled = True\n",
    "\t\t\twhich.append(key)\n",
    "\n",
    "\t# 2) Named vectors under vectorConfig (as in named vectors setups)\n",
    "\tvec_cfg = cls.get(\"vectorConfig\", {}) or {}\n",
    "\tfor _vname, vinfo in vec_cfg.items():\n",
    "\t\tvic = (vinfo or {}).get(\"vectorIndexConfig\", {}) or {}\n",
    "\t\tfor key in (\"bq\", \"pq\", \"rq\", \"sq\"):\n",
    "\t\t\tsub = vic.get(key) or {}\n",
    "\t\t\tif sub.get(\"enabled\") is True:\n",
    "\t\t\t\tcompression_enabled = True\n",
    "\t\t\t\twhich.append(key)\n",
    "\n",
    "\t# Recommendations\n",
    "\tif factor == 1:\n",
    "\t\trep_rec = \"use >= 3 and match number of data nodes (3/5/7/9)\"\n",
    "\telif factor == 3:\n",
    "\t\trep_rec = \"OK for 3-node clusters; if >3 nodes, match node count\"\n",
    "\telif factor in {5, 7, 9}:\n",
    "\t\trep_rec = f\"OK if cluster has {factor} data nodes; otherwise match node count\"\n",
    "\telse:\n",
    "\t\trep_rec = \"match replication factor to number of data nodes\"\n",
    "\n",
    "\tcomp_rec = (\"OK\" if compression_enabled else \"enable one of bq/pq/rq/sq for efficiency\")\n",
    "\n",
    "\tprint(f\"Collection {name}:\")\n",
    "\tprint(f\"replication factor is {factor} -- recommendation is {rep_rec}\")\n",
    "\tprint(f\"Compression is {compression_enabled}{(' (' + ','.join(sorted(set(which))) + ')') if which else ''} -- Recommendation is {comp_rec}\")\n",
    "\tprint()\n",
    "# --- End Replication & Compression Check ---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
